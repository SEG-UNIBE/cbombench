"""
CBOM Storage and Data Handling Utility

This module provides functions for managing data generated by the benchmark tool.
It handles the creation of unique repository identifiers, saving CBOM files and
their corresponding execution metrics, retrieving these metrics, and deleting
all stored data. It uses pathlib for modern, cross-platform path operations.
"""
import json
import os
import hashlib
import shutil
from pathlib import Path
from urllib.parse import urlparse

# --- Constants ---
# Use a Path object for the base directory for all generated data.
BASE_DIR = Path("CBOMdata")


def get_repo_id(url):
    """
    Generates a unique and filesystem-friendly ID for a repository from its URL.

    The ID is derived from the repository name in the URL path. If the path is
    unusual, it falls back to using a hash of the URL to ensure a unique ID.

    Args:
        url (str): The URL of the repository (e.g., https://github.com/owner/repo.git).

    Returns:
        str: A unique identifier for the repository (e.g., "repo").
    """
    try:
        parsed_url = urlparse(url)
        # Extract the path and split it into parts, removing leading/trailing slashes.
        path_parts = parsed_url.path.strip('/').split('/')

        # Use the last part of the path as the repo name (e.g., "repo" from "owner/repo").
        if len(path_parts) >= 2:
            repo_id = path_parts[-1]
        else:
            # Fallback for unusual URLs: use a short hash of the full URL.
            repo_id = hashlib.md5(url.encode()).hexdigest()[:10]

        # Clean up the ID by removing the '.git' suffix if it exists.
        if repo_id.endswith('.git'):
            repo_id = repo_id[:-4]

        return repo_id
    except Exception:
        # Broad exception catch to always return a valid ID, even with malformed URLs.
        return hashlib.md5(url.encode()).hexdigest()[:10]


def save_cbom(cbom, url, tool_name, duration):
    """
    Saves a CBOM document and its execution duration to the filesystem.

    This function creates a JSON file for the CBOM and also records the
    generation time in a separate metrics file.

    Args:
        cbom (dict | list): The CBOM data, typically a dictionary or list.
        url (str): The source URL of the repository for which the CBOM was generated.
        tool_name (str): The name of the tool that generated the CBOM (e.g., 'cbomkit').
        duration (float): The time taken to generate the CBOM, in seconds.

    Returns:
        str: The absolute path to the saved CBOM JSON file.
    """
    # Define the directory for the specific tool (e.g., CBOMdata/cbomkit).
    tool_dir = BASE_DIR / tool_name
    # Create the directory if it doesn't exist, including parent directories.
    tool_dir.mkdir(parents=True, exist_ok=True)

    repo_id = get_repo_id(url)
    cbom_path = tool_dir / f"{repo_id}.json"

    # Save the CBOM data to the JSON file.
    with cbom_path.open('w', encoding='utf-8') as f:
        json.dump(cbom, f, indent=2)

    # If a duration is provided, save it to the metrics file.
    if duration is not None:
        save_duration(url, tool_name, duration)

    return str(cbom_path.resolve())


def save_duration(url, tool_name, duration):
    """
    Saves or updates the execution duration for a repository and tool.

    Metrics are stored in a single JSON file (durations.json). This function
    reads the existing data, updates it with the new duration, and writes it back.

    Args:
        url (str): The source URL of the repository.
        tool_name (str): The name of the tool.
        duration (float): The execution duration in seconds.

    Returns:
        str: The absolute path to the updated metrics JSON file.
    """
    metrics_dir = BASE_DIR / "metrics"
    metrics_dir.mkdir(parents=True, exist_ok=True)
    metrics_path = metrics_dir / "durations.json"

    repo_id = get_repo_id(url)

    # Load existing metrics if the file exists and is valid JSON.
    metrics = {}
    if metrics_path.exists():
        try:
            with metrics_path.open('r', encoding='utf-8') as f:
                metrics = json.load(f)
        except json.JSONDecodeError:
            # If the file is corrupted or empty, start with a new dictionary.
            metrics = {}

    # Update the metrics dictionary with the new data.
    if repo_id not in metrics:
        metrics[repo_id] = {}

    metrics[repo_id][tool_name.lower()] = {
        "duration": round(duration, 2),
        "url": url
    }

    # Write the updated metrics back to the file.
    with metrics_path.open('w', encoding='utf-8') as f:
        json.dump(metrics, f, indent=2)

    return str(metrics_path.resolve())


def get_durations():
    """
    Reads and returns all saved execution durations from the metrics file.

    Returns:
        dict: A dictionary containing all stored duration metrics. Returns an
              empty dictionary if the file doesn't exist or is invalid.
    """
    metrics_path = BASE_DIR / "metrics" / "durations.json"

    if not metrics_path.exists():
        return {}

    try:
        with metrics_path.open('r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError:
        # Return an empty dict if the JSON is malformed.
        return {}


def delete_data():
    """
    Deletes the entire data directory (BASE_DIR), removing all saved CBOMs and metrics.
    """
    if BASE_DIR.exists():
        # shutil.rmtree is used for recursively deleting a directory and its contents.
        shutil.rmtree(BASE_DIR)
        print(f"All data in '{BASE_DIR}' has been deleted.")
    else:
        print(f"Directory '{BASE_DIR}' not found. Nothing to delete.")